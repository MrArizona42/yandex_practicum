# Семантический анализ текстов - поиск токсчиных комментариев

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо обучить модель классифицировать комментарии на позитивные и негативные.

Используемые данные - датасет с 159000 размеченных комментариев.

Минимально необходимый результат: метрика качества F1 не меньше 0.75.

## Используемые инструменты

* numpy
* pandas
* matplotlib.pyplot
* WordCloud

**ML-операции**
* Pipeline
* train_test_split
* LogisticRegression
* GridSearchCV
* tqdm

**Работа с текстом**
* nltk
* spacy
* TfidfVectorizer
* torch
* transformers: BertModel, BertTokenizer

## Общий вывод

**TF-IDF пайплайн:**
1. Токенизация: WordNetLemmatizer и SpaCy.
2. TF-IDF векторизация
3. Обучение модели - Линейная регрессия
4. Подбор порога

Результат: F1 = 0.84

**Bert model пайплайн**
1. Токенизация: `transformers.AutoTokenizer.from_pretrained('unitary/toxic-bert')`
2. Получение эмбеддингов: `transformers.AutoModel.from_pretrained('unitary/toxic-bert')`
3. Обучение модели - Линейная регрессия
4. Подбор порога

Обучение проводилось на локальном GPU NVidia RTX3060 на неполных данных: 30000 комментариев.

Результат: F1 = 0.95

Результат с Bert на тесте: F1 = 0.95